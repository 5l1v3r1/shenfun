TITLE: Shenfun - automating the spectral Galerkin method
AUTHOR: Mikael Mortensen {copyright|CC BY} Email:mikaem@math.uio.no at Department of Mathematics, University of Oslo.
DATE: today

__Summary.__
With the `shenfun` Python module (github.com/spectralDNS/shenfun) an effort is made towards automating the implementation of the spectral Galerkin method for simple tensor product domains, consisting of (currently) one non-periodic and any number of periodic directions. The user interface to `shenfun` is intentionally made very similar to FEniCS (fenicsproject.org). Partial Differential Equations are represented through weak variational forms and solved using efficient direct solvers where available. MPI decomposition is achieved through the `mpi4py-fft` module (bitbucket.org/mpi4py/mpi4py-fft),  and all developed solvers may, with no additional effort, be run on supercomputers using thousands of processors. Complete solvers are shown for the linear Poisson and biharmonic problems, as well as the nonlinear and time-dependent Ginzburg-Landau equation.

## Include table of contents (latex and html; sphinx always has a toc).
## (Lines starting with ## are not propagated to the output file,
## otherwise comments lines starting with # are visible in the
## output file.)

TOC: on

idx{Computational Methods} idx{Spectral} idx{Galerkin} idx{Chebyshev} idx{Legendre}


!split
======= Introduction =======
label{sec:introduction}

The spectral Galerkin method, see, e.g., Shen cite{shen95} or Kopriva cite{kopriva09}, combines spectral basis functions with the Galerkin method and allows for highly accurate solutions on simple, tensor product domains. Due to its accuracy and efficiency, the method is often favoured in studies of sensitive fundamental physical phenomena, where numerical errors needs to be avoided. 

In this paper we will describe the `shenfun` Python module. The purpose of `shenfun` is to simplify the implementation of the spectral Galerkin method, to make it easily accessible to researchers, and to make it easier to solve advanced PDEs on supercomputers, with MPI, in simple tensor product domains. The package can solve equations for tensor product spaces consisting of any number of periodic directions, but, at the moment of writing, only one non-periodic direction. This configuration may sound trivial, but it occurs surprisingly often in physics, for example in plane shear flows like the channel or pipe. And these simple configurations are used heavily to enhance our understanding of fundamental physical processes, like turbulence, or transition to turbulence, turbulent mixing, and turbulent combustion.

The `shenfun` package is heavily influenced by the FEniCS project cite{fenics}, that has made it trivial to solve PDEs in arbitrary complex domains with the finite element method (FEM). FEM also makes use of the Galerin method to set up variational forms. However, where FEM uses basis functions with only local support, the spectral Galerkin method uses basis functions with global support. The local support is one of the many nice features of the FEM, which makes it particularly attractive for unstructured and complex geometries. Spectral methods, on the other hand, are less flexible, but represent the gems of numerical methods, and, whenever possible, when the domain is simple and the solution is smooth, delivers the most accurate approximations.

There are many tools available for working with spectral methods. For MATLAB there is the elegant chebfun package cite{trefethen13}, with an extensive list of application for, e.g., PDEs, ODEs or eigenvalue problems. However, being implemented in MATLAB, there is no feasible extension to DNS and supercomputers through MPI. Numpy and Scipy have modules for orthogonal polynomials (Jacobi, Chebyshev, Legendre, Hermite), and for Fourier transforms, which are both utilized by `shenfun`. The orthogonal module makes it easier to work with Chebyshev and Legendre polynomials, as it delivers, for example, quadrature points and weights for different quadrature rules (e.g., Chebyshev-Gauss, Legendre-Gauss). 

To the author's knowledge, all research codes developed for studying turbulent flows through Direct Numerical Simulations (DNS) on supercomputers have been written in low-level languages like Fortran, C or C++, see, e.g., cite{debruynkops15,hoyas06,leemoser15}, or cite{Alfonsi2016} for a list of high performance channel flow solvers. The codes are  highly tuned and tailored to a specific target, and, being low-level, the codes are not easily accessible to a non-expert programmer. Mortensen and Langtangen cite{Mortensen2016} describe how a DNS solver can be written in Python in 100 lines of script-like code, and also show that the code, when optimized in the background using Cython, runs as fast as an identical C++ implementation on thousands of processors with MPI. {Shenfun} takes it one step further and aims at providing a generic toolbox for creating high performance, parallel solvers of any PDE, in a very high-level language. And without compromising much on computational efficiency. The key to developing such a high-level code in Python is efficient use of Numpy cite{numpy}, with broadcasting and vectorization, and MPI for Python cite{mpi4py}, that wraps almost the entire MPI library, and that can transfer Numpy arrays between thousands of processors at the same speed as a low-level C or Fortran code. Similarly, we utilize the pyFFTW module cite{pyfftw}, that wraps most of the FFTW library cite{libfftw} and makes the FFT as fast when called from Python as it is when used in low-level codes.

#This paper is organised as follows: in Section ref{sec:preliminaries} the spectral Galerkin method is introduced. In Section ref{sec:shenfun} the basics of the {shenfun} package is described and #implementations are shown for simple 1D Poisson and biharmonic problems. In Section ref{sec:tensorproductspaces} we move to higher dimensions and tensor product spaces before we, in #Sections ref{sec:extended} and ref{sec:ginzburg} end with some extended functionality and an implementation for the time dependent nonlinear Ginzburg-Landau equation in 2D.

!split
======= Spectral Galerkin Method =======
label{sec:preliminaries}
The spectral Galerkin method can most easily be described by considering a simple PDE, like the Poisson equation, in a 1D domain $\Omega$
!bt
\begin{equation}
-u''(x) = f(x), \quad x \in \Omega, label{eq:poisson}
\end{equation}
!et
with appropriate boundary conditions (Dirichlet, Neumann or periodic). To solve this equation, we can define a test function $v(x)$ that satisfies the boundary conditions, and that comes with an accompanying weight function $w(x)$. Assuming also that we work with complex valued functions, a weighted continuous inner product of the two functions $u$ and $v$ can be defined as
!bt
\begin{equation}
(u, v)_w = \int_{\Omega} u(x) \overline{v}(x) w(x) dx,
\end{equation}
!et
where $\overline{v}$ is the complex conjugate of $v$. The weighted inner product can now be used to create variational forms. If we multiply Eq. (ref{eq:poisson}) with $\overline{v}w$ and integrate over the domain we obtain the variational form of the PDE
!bt
\begin{equation}
(-u'', v)_w = (f, v)_w. label{eq:weak_poisson}
\end{equation}
!et
The variational form can be solved numerically if $u$ and $v$ are approximated using a finite number $(N)$ of test functions $\{v_l(x)\}_{l=0}^{N-1}$, and a solution 
!bt
\begin{equation}
u(x) = \sum_{l=0}^{N-1} \hat{u}_l v_l(x),
\end{equation}
!et
where $\bs{\hat{u}} = \{\hat{u}_l\}_{l=0}^{N-1}$ are the expansion coefficients, that are also recognised as the unknowns in the modal spectral Galerkin method.

If $v$ is chosen from a Fourier or Legendre basis, then the weight function used in the inner product is simply constant, and we may integrate (ref{eq:weak_poisson}) further using integration by parts. However, for a Chebyshev basis the weight function will be $1/\sqrt{1-x^2}$ and integration by parts is thus usually avoided. The weighted continuous inner product may, depending on the function that is to be integrated, be difficult or costly to evaluate. As such, we will in this work use the weighted \emph{discrete} inner product instead, where the integral is approximated using quadrature
!bt
\begin{equation}
(u, v)_w^N = \sum_{j=0}^{N-1} u(x_j) \overline{v}(x_j) w_j  \approx  \int_{\Omega} u(x) \overline{v}(x) w(x) dx.
label{eq:quadrature}
\end{equation}
!et
Here $\{w_j\}_{j=0}^{N-1}$ represents the quadrature weights and $\{x_j\}_{j=0}^{N-1}$ are the quadrature points for the integration. 

The test functions $v$ will be chosen based in part on boundary conditions. However, regardless of which space the test functions are chosen from, the procedure for solving a PDE with the spectral Galerkin method is always the same:

  * Choose a basis satisfying boundary conditions.
  * Derive variational forms from PDEs using  weighted inner products.
  * Assemble and solve linear systems of equations for expansion coefficients.

In other words it is very much like a finite element method. The major difference is that the basis functions are global, i.e., they all span the entire domain, whereas in FEM the test functions only have local support.


======= Shenfun =======
label{sec:shenfun}
`shenfun` is a Python module package containing tools for working with the spectral Galerkin method. Shenfun implements classes for several bases with different boundary conditions, and within each class there are methods for transforms between spectral and real space, inner products, and for computing matrices arising from bilinear forms in the spectral Galerkin method. The Python module is organized as shown in Figure ref{fig:directorytree}. 

The `shenfun` language is very simple and closely follows that of FEniCS. A simple form implementation provides operators `div, grad, curl` and `Dx`, that act on three different types of basis functions, the `TestFunction`, `TrialFunction` and `Function`. Their usage is very similar to that from FEniCS, but not as general, nor flexible, since we are only conserned with simple tensor product grids and smooth solutions. The usage of these operators and basis functions will become clear in the following subchapters, where we will also describe the `inner` and `project` functions, with functionality as suggested by their names.

FIGURE: [figs/dirtree, height=400 width=200 frac=0.5] Directory tree structure of Python package `shenfun`. label{fig:directorytree}


===== Classes for basis functions ===== 
The following bases are defined in submodules
  * shenfun.chebyshev.bases
    * Basis - Regular Chebyshev 
    * ShenDirichletBasis - Dirichlet boundary conditions
    * ShenNeumannBasis - Neumann boundary conditions (homogeneous)
    * ShenBiharmonicBasis - Homogeneous Dirichlet and Neumann boundary conditions
  * shenfun.legendre.bases
    * Basis - Regular Legendre
    * ShenDirichletBasis - Dirichlet boundary conditions
    * ShenNeumannBasis - Neumann boundary conditions (homogeneous)
    * ShenBiharmonicBasis - Homogeneous Dirichlet and Neumann boundary conditions
  * shenfun.fourier.bases
    * R2CBasis - Real to complex Fourier transforms
    * C2CBasis - Complex to complex transforms

All bases have methods for transforms and inner products on single- or multidimensional Numpy data arrays. The following code shows how to create a Fourier basis and subsequently perform a forward and an inverse discrete Fourier transform on a random array. The `uc` array is only used to test that the transform cycle returns the original data.
!bc pyshell
    >>> from shenfun import *
    >>> import numpy as np
    >>> N = 16
    >>> FFT = fourier.bases.R2CBasis(N, plan=True) 
    >>> u = np.random.random(N)
    >>> uc = u.copy()
    >>> u_hat = FFT.forward(u)
    >>> u = FFT.backward(u_hat) 
    >>> assert np.allclose(u, uc)
!ec

===== Classes for matrices =====
label{sec:matrices}
Matrices that arise with the spectral Galerkin method using Fourier or Shen's modified basis functions (see, e.g., Eqs (ref{eq:chebdirichlet}), (ref{eq:legdirichlet})), are typically sparse and diagonal in structure. The sparse structure allows for a very compact storage, and `shenfun` has its own Matrix-class that is subclassing a Python dictionary, where keys are diagonal offsets, and values are the values along the diagonal. Some of the more important methods of the *SparseMatrix* class are shown below:

!bc pycod
class SparseMatrix(dict):
    def __init__(self, d, shape):
        dict.__init__(self, d)
        self.shape = shape
        
    def diags(self, format='dia'):
        """Return Scipy sparse matrix"""

    def matvec(self, u, x, format='dia', axis=0):
        """Return Matrix vector product self*u in x"""
        
    def solve(self, b, u=None, axis=0):
        """Return solution u to self*u = b"""
!ec

For example, we may declare a tridiagonal matrix of shape N x N as
!bc pycod
    >>> N = 4
    >>> d = {-1: 1, 0: -2, 1: 1}
    >>> A = SparseMatrix(d, (N, N))
!ec
or similarly as
!bc pycod
    >>> d = {-1: np.ones(N-1), 0: -2*np.ones(N)}
    >>> d[1] = d[-1]  # Symmetric, reuse np.ones array
    >>> A = SparseMatrix(d, (N, N))
    >>> A
    {-1: array([ 1.,  1.,  1.]),
      0: array([-2., -2., -2., -2.]),
      1: array([ 1.,  1.,  1.])}
!ec
The matrix is a subclassed dictionary. If you want a regular *Scipy* sparse matrix instead, with all of its associated methods (solve, matrix-vector, etc.), then it is just a matter of
!bc pycod
    >>> A.diags()
    <4x4 sparse matrix of type '<class 'numpy.float64'>'
        with 10 stored elements (3 diagonals) in DIAgonal format>
    >>> A.diags().toarray()
    array([[-2.,  1.,  0.,  0.],
           [ 1., -2.,  1.,  0.],
           [ 0.,  1., -2.,  1.],
           [ 0.,  0.,  1., -2.]])
!ec

===== Variational forms in 1D =====
Weak variational forms are created using test and trial functions, as shown in Section ref{sec:preliminaries}. Test and trial functions can be created for any basis in `shenfun`, as shown below for a Chebyshev Dirichlet basis with 8 quadrature points
!bc pycod
    >>> from shenfun.chebyshev.bases import ShenDirichletBasis
    >>> from shenfun import inner, TestFunction, TrialFunction    
    >>> N = 8
    >>> SD = ShenDirichletBasis(N, plan=True)
    >>> u = TrialFunction(SD)
    >>> v = TestFunction(SD)
!ec
A matrix that is the result of a bilinear form has its own subclass of *SparseMatrix*, called a *SpectralMatrix*. A *SpectralMatrix* is created using *inner* products on test and trial functions, for example the mass matrix:
!bc pycod
    >>> mass = inner(u, v)
    >>> mass
    {-2: array([-1.57079633]),
      0: array([ 4.71238898,  3.1415
                 3.14159265, 3.14159265]),
      2: array([-1.57079633])}
!ec
This *mass* matrix will be the same as Eq. (2.5) of cite{shen95}, and it will be an instance of the *SpectralMatrix* class.
You may notice that *mass* takes advantage of the fact that two diagonals are constant and consequently only stores one single value.

The *inner* method may be used to compute any linear or bilinear form. For example the stiffness matrix *K*
!bc pycod
    >>> K = inner(v, div(grad(u)))
!ec
Square matrices have implemented a solve method that is using fast $\mathcal{O}(N)$ direct LU decomposition or similar, if available, and falls back on using Scipy's solver in CSR format if no better method is found implemented. For example, to solve the linear system *Ku=b*
!bc pycod
    >>> fj = np.random.random(N)
    >>> b = inner(v, fj)
    >>> u = np.zeros_like(b)
    >>> u = K.solve(b, u)
!ec
All methods are designed to work along any dimension of a multidimensional array. Very little differs in the users interface. Consider, for example, the previous example on a three-dimensional cube 
!bc pycod
    >>> fj = np.random.random((N, N, N))
    >>> b = inner(v, fj)
    >>> u = np.zeros_like(b)
    >>> u = K.solve(b, u)
!ec
where *K* is exactly the same as before, from the 1D example. The matrix solve is applied along the first dimension since this is the default behaviour.

The bases also have methods for transforming between spectral and real space. For example, one may project a random vector to the *SD* space using
!bc
    >>> fj = np.random.random(N)
    >>> fk = np.zeros_like(fj)
    >>> fk = SD.forward(fj, fk) # Gets expansion coefficients 
!ec
and back to real physical space again
!bc pycod
    >>> fj = SD.backward(fk, fj)
!ec
Note that *fj* now will be different than the original *fj* since it now has homogeneous boundary conditions. However, if we transfer back and forth one more time, starting from *fj* which is in the Dirichlet function space, then we come back to the same array:
!bc pycod
    >>> fj_copy = fj.copy()
    >>> fk = SD.forward(fj, fk)
    >>> fj = SD.backward(fk, fj)
    >>> assert np.allclose(fj, fj_copy) # Is True
!ec

===== Poisson equation implemented in 1D =====
We have now shown the usage of  $\bf shenfun$ for single, one-dimensional spaces. It does not become really interesting before we start looking into tensor product grids in higher dimensions, but before we go there we revisit the spectral Galerkin method for a 1D Poisson problem, and show how the implementation of this problem can be performed using $\bf shenfun$.

=== Periodic boundary conditions ===
label{sec:fourierpoisson}
If the solution to Eq. (ref{eq:poisson}) is periodic with periodic length $2 \pi$, then we use $\Omega \in [0, 2 \pi]$ and it will be natural to choose the test functions from the space consisting of the Fourier basis functions, i.e.,  $v_l(x)=e^{ilx}$. The mesh $\boldsymbol{x} = \{x_j\}_{j=0}^{N-1}$ will be uniformly spaced 
!bt
\begin{equation}
\boldsymbol{x} = \frac{2 \pi j}{N}  \quad j=0,1,\ldots, N-1,
\end{equation}
!et
and we look for solutions of the form
!bt
\begin{equation}
u(x_j) = \sum_{l=-N/2}^{N/2-1} \hat{u}_l e^{ilx_j} \quad  j=0,1,\ldots N-1.
label{eq:ufourier}
\end{equation}
!et
Note that for Fourier basis functions it is customary (used by both MATLAB and Numpy) to use the wavenumbermesh
!bt
\begin{equation}
\boldsymbol{l} = -N/2, -N/2+1, \ldots, N/2-1, label{eq:wavenumber_even}
\end{equation}
!et
where we have assumed that $N$ is even. Also note that Eq. (ref{eq:ufourier}) naively would be computed in $\mathcal{O}(N^2)$ operations, but that it can be computed much faster $\mathcal{O}(N\log N)$ using the discrete inverse Fourier transform
!bt
\begin{equation}
\bs{u} = \mathcal{F}^{-1}(\bs{\hat{u}}),
\end{equation}
!et
where we use compact notation $\bs{u} = \{u(x_j)\}_{j=0}^{N-1}$.

To solve Eq. (ref{eq:poisson}) with the discrete spectral Galerkin method, we create the basis $V^p = \text{span}\{ e^{ilx} , \text{ for } l \in \boldsymbol{l}\} $ and attempt to find $u \in V^p$ such that
!bt
\begin{equation}
(-u'', v)_w^N = (f, v)_w^N, \quad \forall \, v \in V^p.
\end{equation}
!et
Inserting for Eq. (ref{eq:ufourier}) and using $e^{imx}$ as test function we obtain
!bt
\begin{align}
-(\sum_{l \in \bs{l}} \hat{u}_l (e^{ilx})'', e^{imx})_w^N &= (f(x), e^{imx})_w^N \quad \forall \, m \in \bs{l} \\
\sum_{l \in \bs{l}} l^2( e^{ilx}, e^{imx})_w^N \hat{u}_l &= (f(x), e^{imx})_w ^N\quad \forall \, m \in \bs{l}. label{eq:utmp}
\end{align}
!et
Note that the discrete inner product (ref{eq:quadrature}) is used, and we also need to interpolate the function $f(x)$ onto the grid $\boldsymbol{x}$. For Fourier it becomes very simple since the weight functions are constant $w_j = 2\pi/N$ and we have for the left hand side simply a diagonal matrix
!bt
\begin{equation}
( e^{ilx}, e^{imx})^N = 2\pi \delta_{ml} \quad \text{for} \, l, m \in \bs{l} \times \bs{l},
\end{equation}
!et
where $\delta_{ml}$ is the kronecker delta function.
For the right hand side we have
!bt
\begin{align}
(f(x), e^{imx})^N &= \frac{2 \pi}{N}\sum_{j=0}^{N-1} f(x_j) e^{-imx_j} \quad \text{for } m \in \bs{l}, \\
 &= 2 \pi \mathcal{F}_m(f(\bs{x})), \\
 &= 2 \pi \hat{f}_m,
\end{align}
!et
where $\mathcal{F}$ represents the discrete Fourier transform that is defined as
!bt
\begin{equation}
\hat{u}_l = \frac{1}{N}\sum_{j=0}^{N-1} u(x_j) e^{-ilx_j}, \quad \text{for } l \in \bs{l},
\end{equation}
!et
or simply
!bt
\begin{equation}
  \bs{\hat{u}} = \mathcal{F}(\bs{u}).
\end{equation}
!et
Putting it all together we can set up the assembled linear system of equations for $\hat{u}_l$ in (ref{eq:utmp})
!bt
\begin{equation}
\sum_{l \in \bs{l}}2 \pi l^2 \delta_{ml} \hat{u}_l = 2 \pi \hat{f}_{m} \quad \forall \, m \in \bs{l},
\end{equation}
!et
which is trivially solved since it only involves a diagonal matrix ($\delta_{ml}$), and we obtain
!bt
\begin{equation}
\hat{u}_l = \frac{1}{l^2} \hat{f}_{l} \quad \forall \,l  \in \bs{l} \setminus{\{0\}}.
\end{equation}
!et

So, even though we carefully followed the spectral Galerkin method, we have ended up with the same result that would have been obtained with a Fourier collocation method, where one simply takes the Fourier transform of the Poisson equation and differentiate analytically.

With $\bf shenfun$ the periodic 1D Poisson equation can be trivially computed either with the collocation approach or the spectral Galerkin method. The procedure for the spectral Galerkin method will be shown first, before the entire problem is solved.
 All $\bf shenfun$ demos in this paper will contain a similar preample section where some necessary Python classes, modules and functions are imported. We import Numpy since $\bf shenfun$ arrays are Numpy arrays, and we import from Sympy to construct some exact solution used to verify the code. Note also the similarity to FEniCS with the import of methods and classes $inner, div, grad, TestFunction, TrialFunction$.  The Fourier spectral Galerkin method in turn requires that the `FourierBasis is imported as well. 
!bc pycod
from sympy import Symbol, cos
import numpy as np
from shenfun import inner, div, grad, TestFunction, TrialFunction
from shenfun.fourier.bases import FourierBasis

# Use Sympy to compute a rhs, given an analytical solution
x = Symbol("x")
ue = cos(4*x)
fe = ue.diff(x, 2)

# Create Fourier basis with N basis functions
N = 32
ST = FourierBasis(N, np.float, plan=True)
u = TrialFunction(ST)
v = TestFunction(ST)
X = ST.mesh(N)

# Get f and exact solution on quad points 
fj = np.array([fe.subs(x, j) for j in X], dtype=np.float)
uj = np.array([ue.subs(x, i) for i in X], dtype=np.float)

# Assemble right and left hand sides
f_hat = inner(v, fj)
A = inner(v, div(grad(u)))

# Solve Poisson equation
u_hat = A.solve(f_hat)

# Transfer solution back to real space
uq = ST.backward(u_hat)
assert np.allclose(uj, uq)
!ec

Naturally, this simple problem could be solved easier with a Fourier collocation instead, and  a simple pure 1D Fourier problem does not illuminate the true advantages of  `shenfun`, that only will become evident when we look at higher dimensional problems with tensor product spaces. To solve with collocation, we could simply do
!bc pycod
# Transform right hand side
f_hat = ST.forward(fj)

# Wavenumers
k = ST.wavenumbers(N)
k[0] = 1

# Solve Poisson equation (solution in f_hat)
f_hat /= k**2
!ec

Note that *ST* methods *forward/backward* correspond to forward and inverse discrete Fourier transforms. Furthermore, since the input data *fj* is of type float (not complex), the transforms make use of the symmetry of the Fourier transform of real data, that $\hat{u}_k = \overline{\hat{u}}_{N-k}$, and that $\bs{k}=0,1,\ldots, N/2$ (index set computed as $k = ST.wavenumbers(N)$).

=== Dirichlet boundary conditions ===
label{sec:dirichletpoisson}
If the Poisson equation is subject to Dirichlet boundary conditions on the edge of the domain $\Omega \in [-1, 1]$, then a natural choice is to use Chebyshev or Legendre polynomials. Two test functions that strongly fixes the boundary condition $u(\pm 1)=0$ are
!bt
\begin{equation}
v_l(x) = T_l(x) - T_{l+2}(x),
\end{equation}
!et
where $T_l(x)$ is the l'th order Chebyshev polynomial of the first kind, or
!bt
\begin{equation}
v_l(x) = L_l(x) - L_{l+2}(x),
label{eq:shen_legendre_basis}
\end{equation}
!et
where $L_l(x)$ is the l'th order Legendre polynomial. The test functions give rise to functionspaces
!bt
\begin{align}
V^C &= \text{span}\{T_l-T_{l+2}, l \in \bs{l}^D\}, label{eq:chebdirichlet} \\
V^L &= \text{span}\{L_l-L_{l+2}, k \in \bs{l}^D\}, label{eq:legdirichlet}
\end{align}
!et
where
!bt
\begin{equation}
\boldsymbol{l}^D = 0, 1, \ldots, N-3.
\end{equation}
!et
The computational mesh and associated weights will be decided by the chosen quadrature rule. Here we will go for Gauss quadrature, which leads to the following points and weights for the Chebyshev basis
!bt
\begin{align}
x_j^C &= \cos \left( \frac{2j+1}{2N}\pi \right) \quad &j=0,1,\ldots, N-1, \\
w_j^C &= \frac{\pi}{N},
\end{align}
!et
and
!bt
\begin{align}
x_j^L &= \text{ zeros of }L_{N}(x) \quad &j=0,1,\ldots, N-1, \\
w_j^L &= \frac{2}{(1-x_j^2)[L'_{N}(x_j)]^2} \quad &j=0,1,\ldots, N-1,
\end{align}
!et
for the Legendre basis.

We now follow the same procedure as in Section ref{sec:fourierpoisson} and solve Eq. (ref{eq:poisson}) with the spectral Galerkin method. Consider first the Chebyshev basis and find $u \in V^C$ , such that
!bt
\begin{equation}
(-u'', v)_w^N = (f, v)_w^N , \quad \forall \, v \in V^C.
\end{equation}
!et
We insert for $v=v_m$ and $u=\displaystyle \sum_{l\in \bs{l}^D} \hat{u}_l v_l$ and obtain
!bt
\begin{align}
-(\sum_{l\in \bs{l}^D} \hat{u}_l v_l'', v_m)_w^N &= (f, v_m)_w^N  &m \in \bs{l}^D,\\
-(v_l'', v_m)_w^N \hat{u}_l &= (f, v_m)_w^N & m \in \bs{l}^D, label{eq:cheb_poisson}
\end{align}
!et
where summation on repeated indices is implied. In Eq. (ref{eq:cheb_poisson}) $A_{ml} =(v_l'', v_m)_w^N$ are the components of a sparse stiffness matrix, and we will use matrix notation $\bs{A} = \{A_{ml}\}_{m,l \in \bs{l}^D \times \bs{l}^D}$ to simplify. The right hand side can similarily be assembled to a vector with components $\tilde{f}_m = (f, v_m)_w^N$ such that $\bs{\tilde{f}} = \{\tilde{f}_m\}_{m\in \bs{l}^D} $. Note that a tilde is used since this is not a complete transform. We can now solve for the unknown $\bs{\hat{u}} = \{\hat{u}_l\}_{l\in \bs{l}^D}$ vector
!bt
\begin{align}
-\bs{A} \bs{\hat{u}} &= \bs{\tilde{f}}, \\
   \bs{\hat{u}} &= -\bs{A}^{-1} \bs{\tilde{f}}.
\end{align}
!et
Note that the matrix $\bs{A}$ is a special kind of upper triangular matrix, and that the solution can be obtained very efficiently in approximately $4 N$ arithmetic operations. 

To get the solution back and forth between real and spectral space we require a transformation pair similar to the Fourier transforms. We do this by projection. Start with
!bt
\begin{equation}
u(\bs{x}) = \sum_{l\in \bs{l}^D} \hat{u}_l v_l(\bs{x})
\end{equation}
!et
and take the inner product with $v_m$
!bt
\begin{equation}
(u, v_m)_w^N  = (\sum_{l\in \bs{l}^D} \hat{u}_l v_l, v_m)_w^N.
label{eq:projection}
\end{equation}
!et
Introducing now the mass matrix $B_{ml} = (v_l, v_m)_w^N$ and the \emph{Shen} forward inner product $\mathcal{S}_m(u) = (u, v_m)_w^N$, Eq. (ref{eq:projection})  is rewritten as
!bt
\begin{align}
\mathcal{S}_m(u) &= B_{ml} \hat{u}_l, \\
\bs{\hat{u}}  =& \bs{B}^{-1} \mathcal{S}(\bs{u}) , \\
\bs{\hat{u}}  =& \mathcal{T}(\bs{u}) ,
\end{align}
!et
where $\mathcal{T}(\bs{u})$ represents a forward transform of $\bs{u}$. Note that $\mathcal{S}$ is introduced since the inner product $(u, v_m)_w^N$ may, just like the inner product with the Fourier basis, be computed fast, with $\mathcal{O}(N \log N)$ operations. And to this end, we need to make use of a discrete cosine transform (DCT), instead of the Fourier transform. The details are left out from this paper, though.

A simple Poisson problem with analytical solution $\sin(\pi x)(1-x^2)$ is implemented below, where we also verify that the correct solution is obtained.
!bc pycod
from shenfun.chebyshev.bases import ShenDirichletBasis

# Use sympy to compute a rhs, given an analytical solution
ue = sin(np.pi*x)*(1-x**2)
fe = ue.diff(x, 2)

# Lambdify for faster evaluation
ul = lambdify(x, ue, 'numpy')
fl = lambdify(x, fe, 'numpy')

N = 32
SD = ShenDirichletBasis(N, plan=True)
X = SD.mesh(N)
u = TrialFunction(SD)
v = TestFunction(SD)
fj = fl(X)

# Compute right hand side of Poisson equation
f_hat = inner(v, fj)

# Get left hand side of Poisson equation and solve
A = inner(v, div(grad(u)))
f_hat = A.solve(f_hat)
uj = SD.backward(f_hat)

# Compare with analytical solution
ue = ul(X)
assert np.allclose(uj, ue)
!ec
Note that the inner product `f_hat = inner(v, fj)` is computed under the hood using the fast DCT.  The inverse transform `uj = SD.backward(f_hat)` is also computed using a fast DCT, and we use the notation
!bt
\begin{align}
u(x_j) &= \sum_{l\in \bs{l}^D} \hat{u}_l v_l(x_j) &j=0,1,\ldots, N-1, \notag \\
\bs{u} &= \mathcal{S}^{-1}(\bs{\hat{u}}). label{eq:fast_shen}
\end{align}
!et
To implement the same problem with the Legendre basis (ref{eq:shen_legendre_basis}), all that is needed to change is the first line in the Poisson solver to $from shenfun.legendre.bases import ShenDirichletBasis$. Everything else is exactly the same. However, a fast inner product, like in (ref{eq:fast_shen}), is only implemented for the Chebyshev basis, since there are no known $\mathcal{O}(N \log N)$ algorithms for the Legendre basis, and the Legendre basis thus uses straight forward $\mathcal{O}(N^2)$ algorithms for its transforms.


======= Bibliography =======

## Publish (https://bitbucket.org/logg/publish is used to
## handle references. The line below specifies the name of
## the Publish database file (see the doconce manual for details).

BIBFILE: shenfun.pub
